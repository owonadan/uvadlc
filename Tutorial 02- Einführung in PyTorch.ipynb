{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 2: IntroducEinführung in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Willkommen zu unserem PyTorch-Tutorial für den Deep-Learning-Kurs 2023 an der Universität Amsterdam! Dieses Notebook bietet eine kurze Einführung in die Grundlagen von PyTorch und bereitet dich darauf vor, eigene neuronale Netze zu erstellen. PyTorch ist ein Open-Source-Framework für maschinelles Lernen, das dir flexibles Erstellen und effizientes Optimieren neuronaler Netze ermöglicht. PyTorch ist allerdings nicht das einzige Framework dieser Art. Alternativen sind [TensorFlow](https://www.tensorflow.org/), [JAX](https://github.com/google/jax#quickstart-colab-in-the-cloud) und [Caffe](http://caffe.berkeleyvision.org/). Wir haben uns an der Universität Amsterdam für PyTorch entschieden, da es gut etabliert ist, eine große Entwickler-Community hat (ursprünglich von Facebook entwickelt), sehr flexibel ist und insbesondere in der Forschung eingesetzt wird. Viele aktuelle wissenschaftliche Veröffentlichungen stellen ihren Code in PyTorch bereit, daher ist es von Vorteil, damit vertraut zu sein. TensorFlow (entwickelt von Google) ist hingegen primär als produktionsreife Deep-Learning-Bibliothek bekannt. Wenn du ein Machine-Learning-Framework bereits gut beherrschst, ist es leicht, ein anderes zu erlernen, da viele auf den gleichen Konzepten und Ideen basieren. Zum Beispiel wurde TensorFlow in Version 2 stark von den beliebtesten Features von PyTorch inspiriert, was die Frameworks einander noch ähnlicher gemacht hat. Falls du bereits mit PyTorch vertraut bist und eigene neuronale Netzwerk-Projekte erstellt hast, kannst du dieses Notebook gerne nur überfliegen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natürlich sind wir nicht die Ersten, die ein PyTorch-Tutorial erstellen. Es gibt viele großartige Tutorials im Internet, darunter der [\"60-min blitz\"](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html) auf der offiziellen [PyTorch-Webseite](https://pytorch.org/tutorials/). Dennoch haben wir uns entschieden, ein eigenes Tutorial zu gestalten. Dieses soll dir die Grundlagen vermitteln, die du speziell für unsere praktischen Übungen benötigst, und dir trotzdem ein Verständnis der Funktionsweise von PyTorch geben. Im Laufe der nächsten Wochen werden wir auch weiterhin neue PyTorch-Features in dieser Reihe von Jupyter-Notebook-Tutorials rund um Deep Learning erkunden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir werden einen Satz von Standard-Bibliotheken verwenden, die häufig in Machine-Learning-Projekten genutzt werden. Wenn du dieses Notebook auf Google Colab ausführst, sollten alle Bibliotheken vorinstalliert sein. Falls du das Notebook lokal ausführst, stelle sicher, dass du unsere `d12023`-Umgebung installiert und aktiviert hast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nj/yxgl90t15y58nn503xvrtr4w0000gn/T/ipykernel_81297/47578708.py:11: DeprecationWarning: `set_matplotlib_formats` is deprecated since IPython 7.23, directly use `matplotlib_inline.backend_inline.set_matplotlib_formats()`\n",
      "  set_matplotlib_formats('svg', 'pdf') # For export\n"
     ]
    }
   ],
   "source": [
    "## Standard libraries\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "## Imports for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('svg', 'pdf') # For export\n",
    "from matplotlib.colors import to_rgba\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "## Progress bar\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Die Grundlagen von PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir beginnen mit einem Überblick über die grundlegenden Konzepte von PyTorch. Als Voraussetzung empfehlen wir, mit dem `numpy`-Paket vertraut zu sein, da die meisten Machine-Learning-Frameworks auf sehr ähnlichen Konzepten basieren. Falls du numpy noch nicht kennst, keine Sorge: hier findest du ein [Tutorial](https://numpy.org/devdocs/user/quickstart.html), um dich einzuarbeiten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los geht's! Beginnen wir damit, PyTorch zu importieren. Das Paket heißt `torch`, angelehnt an das ursprüngliche Framework Torch. Als ersten Schritt können wir die Version überprüfen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using torch 2.2.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"Using torch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Zeitpunkt der Erstellung dieses Tutorials (Ende Oktober 2023) ist die aktuelle stabile Version 2.1. Du solltest also als Ausgabe `Using torch 2.1.0` oder `Using torch 2.0.0` sehen, möglicherweise ergänzt durch die Angabe der CUDAVersion auf Colab. Falls du die `d12023`-Umgebung verwendest, solltest du `Using torch 2.1.0` sehen. Generell empfehlen wir, die PyTorch-Version stets auf dem aktuellsten Stand zu halten. Solltest du eine Versionsnummer unter 2.0 sehen, stelle sicher, dass du die richtige Umgebung installiert hast oder frage deine TAs. Im Fall, dass PyTorch 2.2 oder neuer während des Kurses veröffentlicht wird, brauchst du dir keine Sorgen zu machen. Die Schnittstelle zwischen PyTorch-Versionen ändert sich nicht drastisch, daher sollte der Code auch mit neueren Versionen lauffähig sein."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wie in jedem Machine-Learning-Framework bietet PyTorch Funktionen für zufällige Vorgänge, wie die Erzeugung von Zufallszahlen. Es ist jedoch empfehlenswert, deinen Code so zu gestalten, dass Ergebnisse mit denselben Zufallszahlen reproduzierbar sind. Dies ermöglicht es dir, Fehler aufzuspüren und sicherzustellen, dass Änderungen deinerseits (und nicht zufällige Fluktuationen) die Ursache für veränderte Ergebnisse sind. Deshalb setzen wir nachfolgend einen \"Seed\" (Startwert). Der Seed ist der Ausgangspunkt für den Zufallszahlengenerator. Durch Setzen eines festen Seeds stellst du sicher, dass die Sequenz der erzeugten Zufallszahlen immer gleich ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11f21bf30>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(42) # hier setzen wir den seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensoren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensoren sind das PyTorch-Äquivalent zu NumPy-Arrays, bieten aber zusätzlich Unterstützung für GPU-Beschleunigung (dazu später mehr). Der Name \"Tensor\" ist eine Verallgemeinerung von Konzepten, die du bereits kennst. Ein Vektor ist zum Beispiel ein 1D-Tensor und eine Matrix ein 2DTensor. Bei der Arbeit mit neuronalen Netzen verwenden wir Tensoren unterschiedlicher Formen und Dimensionen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die meisten gängigen Funktionen, die du von NumPy kennst, können auch auf Tensoren angewendet werden. Da NumPy-Arrays und Tensoren sich stark ähneln, können wir die meisten Tensoren in NumPy-Arrays (und umgekehrt) umwandeln. Dies ist jedoch in der Regel nicht oft notwendig."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialisierung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fangen wir damit an, uns verschiedene Möglichkeiten zur Erstellung eines Tensors anzusehen. Es gibt viele Optionen, die einfachste ist der Aufruf von `torch.Tensor` mit der gewünschten Form als Eingabeparameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.Tensor(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Funktion `torch.Tensor` weist den gewünschten Speicher für den Tensor zu, verwendet aber bereits vorhandene Speicherinhalte ggf. weiter. Um dem Tensor direkt bei der Initialisierung Werte zuzuweisen, gibt es verschiedene Möglichkeiten, darunter:\n",
    "- `torch.zeros`: Erzeugt einen Tensor gefüllt mit Nullen.\n",
    "- `torch.ones`: Erzeugt einen Tensor gefüllt mit Einsen.\n",
    "- `torch.rand`: Erzeugt einen Tensor mit Zufallswerten, die gleichmäßig zwischen 0 und 1 verteilt sind.\n",
    "- `torch.randn`: Erzeugt einen Tensor mit Zufallswerten, die einer Normalverteilung mit Mittelwert 0 und Varianz 1 folgen.\n",
    "- `torch.arange`: Erzeugt einen Tensor mit den Werten $N, N+1, N+2, \\ldots, M$\n",
    "- `torch.Tensor` (input list): Erzeugt einen Tensor aus einer von dir bereitgestellten Liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor aus (verschachtelter) Liste erzeugen\n",
    "x = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "         [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "         [0.9408, 0.1332, 0.9346, 0.5936]],\n",
      "\n",
      "        [[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "         [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "         [0.2696, 0.4414, 0.2969, 0.8317]]])\n"
     ]
    }
   ],
   "source": [
    "# Erstelle einen Tensor mit Zufallswerten zwischen 0 und 1 mit der Form [2, 3, 4]\n",
    "x = torch.rand(2, 3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamische Berechnungsgraphen und Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU-Unterstützung/GPU-Beschleunigung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lernen durch Beispiele: Kontinuierliches XOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusätzliche Features, die wir noch nicht besprochen haben"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uvadlc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
